NAME: 
Arjun Bamba; JHED ID: abamba1

MODULE INFO: 
Module 2 - Web Scraping
Assignment 2
September 7, 2025

APPROACH:
Checking robots.txt:
![robots.txt](/Screenshot_robots_txt.jpg)

Initial Setup: 
I have tracked dependencies using requirements.txt via:
1. `pip freeze > requirements.txt`
This file lists all installed packages and their versions.

To run the project:
1. Clone the repo.
2. In terminal, navigate to within module_2 directory in cloned repo.
3. Through terminal, recreate the venv and install dependencies:
    (a) Create your new venv: `python3 -m venv venv`
    (b) Activate it: `source venv/bin/activate`
        (*) For reference, I installed packages in an active venv like this: `python3 -m pip install urllib3`
    (c) Install dependencies so your environment matches mine exactly: `pip install -r requirements.txt`
4. Run the project: `python main.py`
5. In terminal, after finished running the project, deactivate venv through: `deactivate`

KNOWN BUGS
Not Applicable
